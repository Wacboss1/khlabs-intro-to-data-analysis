{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start anything. We need to download the libarries that we plan on using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all of our libaries are downloaded and imported, we can start importing our data\n",
    "\n",
    "For this lab we are going to be working with an excel spreadsheet of trending youtube videos in the United States \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data\n",
    "before we can do anything with the data, we must but it into a pandas dataFrame so that we can easily view and manipulate the data.\n",
    "\n",
    "Since the data is in an CSV (Comma Seperated Values) document, we will use `pd.read_csv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis always start with a question we want to solve. \n",
    "\n",
    "For this workshop, we are going to try to answer the following questions\n",
    "- who has made the most trending videos?\n",
    "- what are the most common words in a trending title?\n",
    "- what is the best time to post a video if we want it to be trending?\n",
    "\n",
    "However, before we can start answering any of these quesitons, we are going to need gain a better understanding of our data through a process called <b>data exploration<b/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Our Data\n",
    "Before we start doing any form of analysis we want to get a better understanding of the data that we are working with."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will start by calling `.info()` on our dataframe to learn more about each column of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that the 40949 rows.\n",
    "\n",
    "We can also tell that\n",
    "- not every row has a description because the number of non-null rows is less than the number of rows\n",
    "- We are working with 3 booleans columns, 5 integers columns, and 8 strings (objects)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check duplicates\n",
    "\n",
    "We also want to see how many duplicates we have in our data\n",
    "\n",
    "we can do this using the `.duplicated().sum()`\n",
    "this is a combination of two methods\n",
    "- `.duplicated()` which create a list of booleans based on if that row show up somewhere else in the dataframe\n",
    "- `.sum()` which adds all the True (1) and falses (0) together.\n",
    "  \n",
    "adding these to methods at the end of our dataframe will count the number rows that share values accross every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that there are 48 rows that have all the same values as some other row in the dateset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to check for rows that share values over specifc columns, we can pass as list of the columns we want to check\n",
    "\n",
    "for example <br/>\n",
    "`df.duplicated([\"column_name\"]).sum()`|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally,\n",
    "\n",
    "we are going to use another method called `.describe()`.\n",
    "\n",
    "This function will give us a more quantiative understanding of our 5 integer columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the key information we get from this table is\n",
    "- 549 is the least amount of views any our our videos have\n",
    "- 5,613,827 is the most likes that any of our videos have"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have taken a basic look at the data we are working with, try to come up with some question you would want to answer.\n",
    "\n",
    "for example: Is the video with the least amount fo views also the one with the least amount of likes?\n",
    "\n",
    "Once you are done with this lab, come back to the questions you had and see if you could answer them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who has made the most trending videos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to solve this particular question we are going to need a list of all the videos.\n",
    "\n",
    "However, we want to make sure that every video is only showing up once.\n",
    "\n",
    "we are going to use `df.duplicated` again but this time we will list the columns we want to check for duplicates on and then use that list as a parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that there are 34433 rows that share a title and a channel title with some other row in the dataset.\n",
    "\n",
    "Once again we are going to drop these rows using `df.drop_duplicates()` but we will pass our list of columns to it like we did `df.duplicated()`\n",
    "\n",
    "*Be aware that `df.drop_duplicates()` will keep the first row it finds and delete any duplicates afterwards. If you want to keep the last ones, use `df.drop_duplicates(COL_TO_CHECK,keep='last')`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets count the duplicates again to make sure that we got rid of everything that we wanted to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the value is zero than we have set everything up corrent and can now continue with the analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, we need to put all of our rows of data into groups based on the channel that made the video.\n",
    "\n",
    "We can do this by using `df.groupby(by=['channel_title'])` and then use `.size()` on the result to get the number of rows in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we just need to sort these groups using `.sort_values()` make sure to set the ascending parameter to false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what are the most common words in trending titles?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that we have to do is make sure that every title is only represented once. So once again, we are going use the `df.drop_duplicates()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be able to create new rows so we are going to change this from a series to a dataframe\n",
    "\n",
    "we can see the type of a variable by using `type()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to create a new method that will take in a given row and create a new column for each word containg the number of times is appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the method has been made, we can use it on our dataframe with `df.apply()`\n",
    "\n",
    "because we wrote our function to take  in a row, we also want to set the axis paramater to 1. Otherwise it would go column by column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a column for each word that has ever shown up in a title. \n",
    "\n",
    "However, the words that don't show up are set a NaN which is not very helpful\n",
    "\n",
    "Lets set these as 0 by using `df.fillna(0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we only have two more steps to go\n",
    "\n",
    "we are going to need to switch the rows and the columns so that we can easily do a sum\n",
    "\n",
    "using `.transpose()` on are dataframe will do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add up the columns to for each row and sort them by using `df.apply(sum, axis=1)` and `df.sort_values(ascending=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now before we go continue, thing about the answer that we recieved.\n",
    "\n",
    "Is this answer useful? Why or Why not?\n",
    "\n",
    "If the answer is not useful, after finishing this workshop, come back to this and try to get a better answer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the best time to post a video"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question, we are going to figure out what hour of the day most of our videos were published.\n",
    "\n",
    "To start we are going to need to make sure that the published time for each row is a datetime.\n",
    "\n",
    "We can check this by using `type()` on `df['published_time'][0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since published time seems to be a string, we are going to use `df.apply()` again and set `pd.to_datetime` as the function to apply\n",
    "\n",
    "This will change every value in 'published_time' into a datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are going to use the `apply()` method again to create a new columns for the hour that each video was posted on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to make a function called get_hour_published that takes in a datetime and returns the hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can take a want to create a new column called hour_published that will be the output of applying our get_hour_published function on our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets make a plot a histogram of our data so that we can see how our data is spread out.\n",
    "\n",
    "while there a plenty of better libaries for making graphs, we can just use pandas `df.plot.hist()`\n",
    "\n",
    "since there are 24 hours in a day, we will set the bin so 24 so each our has it own bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will use `df..groupby().size()` to get the number of times each hour occurs and sort it in decending order using `df.sort_values(ascending=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conlcusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with that you have experience the basics of data exploration and analysis.\n",
    "\n",
    "We are just scratching the surface with what can be solved with this dataset but hopefully the concepts and technique we covered can help you make your own data analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25068545605cc3a54964cc63fbd0e23ad796b0d4fcd587652a1759f080719adc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
